{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install pandas pyarrow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import pandas as pd\n",
    "import gzip\n",
    "import ast\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#archivo: \"C:\\Users\\Usuario\\Henry\\PI01MLOPs\\DataSet\\Users_items\\users_items.json.gz\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Desarrollo función leer_Json_gzip() que lee los archivos 'comprimidos.json.gz` y devuelve una lista de diccionarios Python.\n",
    "def leer_json_gzip(users_items):\n",
    "\n",
    "    # Abrir el archivo users_items.json.gz en modo de lectura y decodificamos el contenido del archivo.\n",
    "    with gzip.open(users_items, 'rt', encoding='utf-8') as miArchivo:\n",
    "\n",
    "        # Recorremos el contenido del archivo y evaluamos cada línea como una expresión Python.\n",
    "        # El resultado de la evaluación es un diccionario Python.\n",
    "        # La función strip() elimina los espacios en blanco al principio y al final de la línea.\n",
    "        return [ast.literal_eval(line.strip()) for line in miArchivo]\n",
    "    #Usamos ast.literal_eval para convertir cada linea en un diccionario y lo agregamos a la lista"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "datos_users_items = []\n",
    "for i  in gzip.open('users_items.json.gz'):\n",
    "    datos_users_items.append(ast.literal_eval(i.decode('utf-8')))\n",
    "\n",
    "DataFrame_users_items = pd.DataFrame(datos_users_items)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DataFrame_users_items"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "DataFrame_users_items.to_parquet('users_items.parquet', engine='pyarrow')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DataFrame_users_items.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tipo de datos de la columna 'items': object\n"
     ]
    }
   ],
   "source": [
    "#Revisé el tipo de datos que hay en cada columna\n",
    "tipo_de_datos_columna_items_count = DataFrame_users_items['items'].dtype\n",
    "print(\"Tipo de datos de la columna 'items':\", tipo_de_datos_columna_items_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dado que el archivo esta muy largo no desanidaré la columna hasta que el enunciado no lo indique y queda asi el archivo que ya está manejable\n",
    "# Al hacer la función veo que debo desanidar columna \"items\" para encontrar el tiempo jugado\n",
    "\n",
    "DataFrame_users_items_exploded = DataFrame_users_items.explode('items')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalizo los datos y creo un nuevo data frame desanidado\n",
    "DataFrame_users_items_desanidado = pd.json_normalize(DataFrame_users_items_exploded['items'].dropna())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Volver a indexar\n",
    "DataFrame_users_items_desanidado.reset_index(inplace=True)\n",
    "DataFrame_users_items_exploded.reset_index(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#  Concateno Data Frames y borro columna original items\n",
    "user_items_final = pd.concat([DataFrame_users_items_exploded, DataFrame_users_items_desanidado], axis=1)\n",
    "df_user_item_final =  user_items_final.drop(columns=['items'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#vuelvo a hacer datframe con los datos del archivo steam_games\n",
    "# le pego el data frame de steam_games, le qiuto nulos otra vez, asi que traje el dataFrame del archico users:items\n",
    "\n",
    "df_steam_games = pd.read_json(\"steam_games.json.gz\" , lines=True)\n",
    "df_steam_games_sinnulos = df_steam_games.dropna()\n",
    "DataFrame_users_items_desanidado = pd.json_normalize(DataFrame_users_items_exploded['items'].dropna())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DataFrame_users_items_desanidado"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transformo el año que resultó del explode a numero para que se le quite el punto\n",
    "\n",
    "df_steam_games_sinnulos_Exploded = df_steam_games_sinnulos.explode('tags')\n",
    "df_steam_games_sinnulos_Exploded['release_date'] = pd.to_datetime(df_steam_games_sinnulos_Exploded['release_date'], errors='coerce')\n",
    "df_steam_games_sinnulos_Exploded['release_year'] = df_steam_games_sinnulos_Exploded['release_date'].dt.year\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Trato de vincular  las etiquetas de columna df_steam_games_sinnulos_Exploded con la columna DataFrame_users_items_desanidado item_name usando  Pandas.\n",
    "\n",
    "Me doy cuenta que el contenido de la columna app_name en streams es el mismo que item_name en user_items así que a travez de esa columna hago el merge\n",
    "\n",
    "Entonces creo la fusion usando merge así: merged_df = df1.merge(df2, on='app_name', how='inner')\n",
    "\n",
    "En este caso tenemos dos Data Frames  de datos que se entrelazan con dos nombres de columnas diferentes. \n",
    "\n",
    "merged_df = df1.merge(df2, left_on='titapp_namele', right_on='item', how='inner'), donde 'app_name' es una columna en df1 y el item_name está en el dataframe df2.\n",
    "\n",
    "entonces creo  un nuevo data frame que une 2 data frames  usando dos nombres de campo:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "merged_df = df_steam_games_sinnulos_Exploded.merge(DataFrame_users_items_desanidado, left_on='app_name', right_on='item_name', how='inner')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# aca defino la función según la consigna, en este caso es la función1\n",
    "\n",
    "def PlayTimeGenre(merged_df, genre):\n",
    "\n",
    "    # Filtrar el DataFrame para incluir solo filas con el género especificado con tags que tiene la misma información de genres\n",
    "\n",
    "    genre_df = merged_df[merged_df['tags'] == genre]\n",
    "\n",
    "    if genre_df.empty:\n",
    "        return \"No hay datos para este genero.\"\n",
    "\n",
    "    # Se agrupa el DataFrame filtrado por 'año_lanzamiento' y busque el año con el tiempo de reproducción máximo\n",
    "\n",
    "    max_playtime_year = genre_df.groupby('release_year')['playtime_forever'].sum().idxmax()\n",
    "\n",
    "    return max_playtime_year"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Teniendo todos los datos en la misma tabla se pueden hacer las consultas necesarias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "El año con la mayor cantidad de horas jugadas de Free to Play es 2013.0.\n"
     ]
    }
   ],
   "source": [
    "genres = \"Free to Play\"  # Se ppuede reemplazar con el género que se desea consultar\n",
    "year_with_max_playtime = PlayTimeGenre(merged_df, genres)\n",
    "print(f\"El año con la mayor cantidad de horas jugadas de {genres} es {year_with_max_playtime}.\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
